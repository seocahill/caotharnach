<!-- index.erb -->
<!DOCTYPE html>
<html color-mode="user">
  <head>
    <title>Speech Recognition and Text-to-Speech App</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <link rel="stylesheet" href="https://unpkg.com/mvp.css">
    <link rel="icon" href="data:,"> <!-- Add this line to prevent favicon request -->

  </head>
  <body>
    <main>
      <h1>Cuir ceist ar an gCaotharnach!</h1>
      <p>Have a voice chat with "open" ai.</p>
      <details open>
        <summary>Treoracha / instructions</summary>
        <ol>
          <li>Hit "Tosaigh" to start the voice chat.</li>
          <li>Hit "Druid" to close the chat.</li>
          <li>Hit "Glan" to reset the chat history.</li>
          <li>You can change the default prompt and voice by going to "Socruithe", hitting "Taispeáin" and finally "Athraigh". </li>
        </ol>
      </details>
      <h2>Comhrá</h2>
      <div id="chatContainer">
        <div id="conversationList"></div>
        <div id="inputContainer">
          <button id="recordBtn">Tosaigh</button>
          <button id="hangUpBtn" style="display:none;">Druid</button>
          <button id="glanBtn" onClick="window.location.reload();">Glan</button>
        </div>
      </div>
      <hr>
      <h2>Socruithe</h2>
      <details>
        <summary>Taispeáin</summary>
        <i>Sa trialacha a ndearna mé, oibríonn treoracha i mBéarla níos fearr. Níl a fhios agam cén fáth.</i>
        <form action="/set_context" method="post">
        <label for="context">Comhthéacs:</label>
        <textarea name="context" id="context" cols="30" rows="10"><%= @context %></textarea>
        <label for="guth">Sórt Guth:</label>
        <select id="guth" name="guth">
          <option value="ga_UL_anb_nemo" <% if @guth == "ga_UL_anb_nemo" %>selected<% end %>>Tír Chonaill</option>
          <option value="ga_MU_nnc_nemo" <% if @guth == "ga_MU_nnc_nemo" %>selected<% end %>>Cíarraí</option>
        </select>
        <input type="submit" value="Athraigh an comhthéacs">
      </form>
      </details>
    </main>
    <footer>
      <p>
        <a href="https://github.com/seocahill/caotharnach">Fórc anseo.</a>
      </p>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script>
      $(document).ready(function() {
        const conversationList = document.getElementById('conversationList');
        const recordBtn = document.getElementById('recordBtn');
        const hangUpBtn = document.getElementById('hangUpBtn');
        const glanBtn = document.getElementById('glanBtn');


        recordBtn.addEventListener('click', toggleRecording);
        hangUpBtn.addEventListener('click', hangUp);

        let isRecording = false;
        let mediaRecorder;
        let hasHungUp = false;
        let stream;

        async function toggleRecording() {
          if (!isRecording) {
            startRecording();
            hangUpBtn.style.display = 'inline';
            glanBtn.style.display = 'none';
            hasHungUp = false;
          } else {
            stopRecording();
          }
        }

        async function startRecording() {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);
          const audioContext = new AudioContext();
          const source = audioContext.createMediaStreamSource(stream);
          const analyser = audioContext.createAnalyser();
          source.connect(analyser);

          analyser.fftSize = 256;
          const bufferLength = analyser.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);

          let silenceStart = performance.now();
          const silenceThreshold = 0.02; // Adjusted threshold
          const silenceDuration = 2000; // Adjusted duration

          function calculateRMS(dataArray) {
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
              const value = (dataArray[i] - 128) / 128;
              sum += value * value;
            }
            return Math.sqrt(sum / dataArray.length);
          }

          function detectSilence() {
            analyser.getByteTimeDomainData(dataArray);
            const rms = calculateRMS(dataArray);

            if (rms < silenceThreshold) {
              if (performance.now() - silenceStart > silenceDuration) {
                console.log('User has stopped speaking');
                stopRecording();
              }
            } else {
              silenceStart = performance.now();
            }

            if (isRecording) {
              requestAnimationFrame(detectSilence);
            }
          }

          let audioChunks = [];

          mediaRecorder.onstart = () => {
            console.log('Recording started');
            isRecording = true;
            recordBtn.textContent = 'Ag Éisteacht...';
            recordBtn.style.backgroundColor = 'red';
            detectSilence();
          };

          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              audioChunks.push(event.data);
            }
          };

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            console.log('Audio data available:', audioBlob);
            await processAudio(audioBlob);
          };

          mediaRecorder.start();
        }

        function stopRecording() {
          if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            recordBtn.textContent = 'Ag Fanacht ar Freagra...';
            recordBtn.style.backgroundColor = 'green'
          }

          // Stop all media tracks to release the microphone
         if (stream) {
             stream.getTracks().forEach(track => track.stop());
             stream = null;
         }
        }

        async function processAudio(audioBlob) {
          if (hasHungUp) {
              console.log('Hang up detected, skipping audio processing');
              return; // Prevent further processing if the user has hung up
          }
          try {
            const audioString = await blobToBase64(audioBlob);
            const response = await fetch('/forward_audio', {
              method: 'POST',
              body: JSON.stringify({ audio_blob: audioString }),
              headers: {
                'Content-Type': 'application/json'
              }
            });

            const data = await response.json();
            const audioContent = data.audioContent;

            // Play the audio response
            const audio = new Audio("data:audio/wav;base64," + audioContent);
            audio.play();


            // Update conversation from server
            await updateConversation();

            // Reset button text
            recordBtn.textContent = 'Tosaigh';

            // Automatically start recording again after the response is played
            audio.onended = () => {
              if (!isRecording && !hasHungUp) {
                startRecording();
              }
            };
          } catch (error) {
            console.error('Error processing audio:', error);
            recordBtn.textContent = 'Tosaigh';
          }
        }

        async function updateConversation() {
          try {
            const response = await fetch('/get_context');
            const contextData = await response.json();

            // Assuming contextData is an array containing the last two context items
            contextData.forEach(item => {
              if (item.content) { // Check if content is not empty
                const title = document.createElement('dt');
                const data = document.createElement('dd');
                data.textContent = item.content;
                if (item.role === 'user') {
                  title.textContent = "Tusa:";
                } else {
                  title.textContent = "Sise:";
                }
                conversationList.appendChild(title);
                conversationList.appendChild(data);
              }
            });
            conversationList.scrollTop = conversationList.scrollHeight;
          } catch (error) {
            console.error('Error fetching context:', error);
          }
        }

        async function blobToBase64(blob) {
          return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onloadend = () => resolve(reader.result.split(',')[1]);
            reader.onerror = reject;
            reader.readAsDataURL(blob);
          });
        }

        function hangUp() {
          if (isRecording) {
            stopRecording();
          }
          hasHungUp = true;
          hangUpBtn.style.display = 'none';
          recordBtn.textContent = 'Tosaigh';
          glanBtn.style.display = 'inline'
          recordBtn.style.backgroundColor = '';
        }
      });
    </script>
    <style>
      #inputContainer {
        display: flex;
        gap: 10px; /* Adjust the gap as needed */
        padding: 10px;
        flex-wrap: wrap; /* Allow wrapping on smaller screens */
      }
      #chatContainer {
        display: flex;
        flex-direction: column;
        height: 400px;
        border: 1px solid #ccc;
        border-radius: 5px;
      }
      #conversationList {
        flex-grow: 1;
        overflow-y: auto;
        padding: 10px;
      }
      @media (max-width: 600px) {
        #chatContainer {
          height: 40vh; /* Increase height for smaller screens */
        }
        #inputContainer {
          flex-direction: column; /* Stack buttons vertically on smaller screens */
        }
        #inputContainer button {
          width: 100%; /* Make buttons full width */
          padding: 10px; /* Adjust padding for smaller buttons */
        }
      }
    </style>
  </body>
</html>
